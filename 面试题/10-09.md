# 10月9号

## （1）说一下缓存三兄弟分别造成的原因和解决方案？

缓存三兄弟指的是缓存穿透、缓存击穿和缓存雪崩。

### 造成原因

- **缓存穿透**：原因是因为查询一个不存在的数据，缓存中没有命中，直接穿透到数据库，导致数据库压力大。如果是恶意攻击（如大量查询不存在的键），会更严重。
- **缓存击穿**：原因是一个热点键（高并发访问）突然过期，大量请求同时打到数据库。
- **缓存雪崩**：原因是一大批键同时过期，导致请求洪峰打到数据库。

### 解决方案

- **缓存穿透**：
  - 1）用布隆过滤器（Bloom Filter）在入口处过滤不存在的键，我项目中可以用它来预判用户ID是否存在；
    - ~~如何预判？~~
  - 2）缓存空值，比如查到数据库为空时，缓存一个空对象或null，并设置短过期时间（如5分钟），避免反复穿透；
  - 3）加强参数校验，前端或网关层过滤无效请求。
- **缓存击穿**：
  - 1）用分布式锁（如Redis的Redisson）在缓存失效时，只让一个线程去数据库加载，其他线程等待；
  - ~~2）设置热点键永不过期，或用逻辑过期（在值中加过期时间字段，手动检查）；~~  
    - 会带来其他问题，比如：用户可能会看到旧数据，如何去主动更新Redis数据
  - 3）预热缓存，在系统启动或定时任务中加载热点数据。
    - 优点：
    - 缺点：缓存预热时，如果数据量大，可能导致启动慢，需要用异步任务优化。
- **缓存雪崩**：
  - 1）过期时间加随机值（如基数+随机数），避免同时失效；
  - 2）多级缓存（如JVM本地缓存Caffeine + Redis），本地缓存作为备份；
  - ~~3）限流降级，用Sentinel或Hystrix在高负载时熔断请求；~~

> [!warning]
>
> 可能会问：
>
> - ~~布隆过滤器误判率怎么控制？（通过调整哈希函数数量和位数组大小）~~



## （2）项目中一般用redis来做什么？做缓存的情况下那你们怎么保证数据库和缓存的的一致性？

在我的医疗设备健康平台项目中，Redis主要用于几个场景：

- 1）作为缓存，存储热点数据如用户疗程列表、设备最新上报数据（用String或Hash结构），减少数据库压力；
- 2）分布式锁，比如在积分扣减时用Redisson防止并发问题；
- ~~3）消息队列的补充（如用List实现简单队列），不过我们主要用RabbitMQ；~~
- 4）会话管理，存储用户Token（用String，设置过期时间）；
- 5）计数器，如设备异常报警计数（用Incr命令）。

做缓存时，保证数据库和Redis一致性是关键，我们用的是“延迟双删”策略结合MQ异步更新。

具体流程：

读时先查Redis，命中返回；未命中查MySQL，查到后写入Redis。

写时（更新/删除数据）：

1. 先删Redis缓存；
2. 更新MySQL；
3. 用RabbitMQ发延迟消息（延时5-10秒），再删一次Redis（防止读写并发导致脏数据）。

> [!tip]
>
> 为什么延迟删？
>
> 因为更新MySQL可能慢，先删缓存避免旧数据被读到，延迟删处理极端情况。

~~其他一致性方案：我们没用Canal监听Binlog同步（因为项目规模小，引入复杂），但如果数据量大，可以考虑。~~



## （3）说一下cap定理和base理论？

CAP定理是分布式系统设计的基础，由Eric Brewer提出，指Consistency（一致性）、Availability（可用性）、Partition tolerance（分区容错性）三者不可兼得，只能取其二。在网络分区（P）不可避免时，要在C和A间权衡。

- **Consistency**：所有节点同一时刻数据一致，如银行转账必须强一致。
- **Availability**：每个请求都能得到响应，不允许 downtime。
- **Partition tolerance**：系统在网络分区时仍能运行。

例如，MySQL主从复制偏CP（主库写，从库读，但分区时可能不一致）；Redis集群偏AP（异步复制，分区时可用但不强一致）。

BASE理论是eBay的Dan Pritchett基于CAP的实际应用，是Basically Available（基本可用）、Soft state（软状态）、Eventually consistent（最终一致性）的缩写。强调在分布式系统中牺牲强一致，转而追求高可用和最终一致，适合电商、社交等场景。

~~项目中，我们的微服务用Nacos（AP模型），订单服务追求最终一致（用MQ异步），而用户登录用Redis锁追求强一致（CP）。~~



## （4）你项目中哪里用到了分布式事务？你们这个场景为什么选择at模式不选择其他模式？说一下seata的at模式原理？

在项目中，分布式事务主要用在订单支付场景：用户支付后，需要扣减积分（会员服务）、更新订单状态（订单服务）、发短信通知（消息服务），这些跨微服务，用Seata保证一致性。

为什么选择AT模式：AT（Automatic Transaction）是Seata的默认模式，适合我们这种对一致性要求不高但开发简单的场景（最终一致够用）。不像TCC（Try-Confirm-Cancel）需要手动写补偿逻辑，侵入性强；SAGA适合长事务，但我们的事务链短；XA太重，性能差。我们订单不是金融级强一致，AT的自动回滚和低侵入性正好（只需加@GlobalTransactional注解）。

Seata AT模式原理：基于两阶段提交（2PC）。第一阶段（Prepare）：事务协调器（TC）通知资源管理器（RM）执行本地事务，RM用Undo Log记录回滚镜像（before/after image），但不提交；第二阶段（Commit/Rollback）：如果所有RM成功，TC通知Commit；任意失败，TC通知Rollback，用Undo Log自动回滚。~~分支事务用Branch Table记录，全局用Global Table管理。Seata Server（TC）用DB/Redis/File存储事务状态。~~



## （5）深拷贝和浅拷贝的区别？怎么实现深拷贝？

浅拷贝和深拷贝是对象复制的两种方式，区别在于处理引用类型属性时。

- **浅拷贝**：只复制基本类型（如int、String）的值，对于引用类型（如对象、数组），复制的是引用地址。新旧对象共享同一内存，修改一个会影响另一个。适合简单对象，但容易导致意外修改。Java中Object.clone()默认是浅拷贝（需实现Cloneable接口）。
- **深拷贝**：复制整个对象图，包括所有引用类型的内部对象。新对象完全独立，修改不影响源对象。适合复杂嵌套对象，如项目中的用户对象（含设备列表）。

### 如何实现深拷贝？

> [!tip]
>
> 深度复制的方式：
>
> 1. **手动深度复制**：通过手动复制每个属性，确保引用类型的属性是通过新对象来复制。
> 2. **序列化**和**反序列化**：使用 `ByteArrayOutputStream` 和 `ObjectInputStream` 将对象转化为字节流，再反序列化回新对象，从而实现深度复制。
> 3. **工具库**：使用 Apache Commons Lang 提供的 `SerializationUtils` 来简化深度复制的实现。

---

1. 手动实现（推荐在性能敏感的场景中使用）

最直接的方式：**手写构造函数 / 工厂方法**复制所有字段，包括引用类型。

**优点：**

- 可控性强、性能高。
- 无需序列化依赖。

**缺点：**

- 对象字段多时代码冗长。
- 一旦类结构变动，要同步修改。

---

2. 实现 `Cloneable` 接口并重写 `clone()`

Java 自带的“拷贝接口”，但默认是**浅拷贝**，要自己递归修改成深拷贝。

**优点：**

- 不用引入额外库。
- 支持复杂嵌套结构。

**缺点：**

- `Cloneable` 本身设计不优雅。
- `clone()` 是受保护方法、语义混乱。
- 需要处理 `CloneNotSupportedException`。

> ✅ 实际项目中推荐自定义 `deepClone()` 方法而不是直接复用 `clone()`。

---

3.  通过序列化实现（最通用、但性能略低）

利用序列化的特性把对象完全转成字节流再还原，可实现真正意义上的深拷贝。

（1）Java原生序列化（`Serializable`）

**优点：**

- 代码最简单。
- 支持任意复杂对象结构。

**缺点：**

- 必须实现 `Serializable`。
- 性能较低。

（2）使用第三方库（如 Apache Commons Lang）

Apache Commons Lang 提供了 `SerializationUtils.clone()` 方法，内部也是序列化实现。

**优点：**

- 一行搞定。
- 简洁可靠。

**缺点：**

- 依赖外部库。

---

4. 使用 JSON 序列化（简便、兼容性强）

常用于前后端交互对象复制，比如用 `Jackson` 或 `Gson`。

**优点：**

- 简单直观。
- 不依赖 `Serializable`。
- 兼容多语言对象结构。

**缺点：**

- 序列化/反序列化性能一般。
- 丢失 transient 字段或类型信息（复杂泛型不建议）。